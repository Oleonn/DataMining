{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xKjUNPrd0NWJ",
        "kfsXl1-PjSZF",
        "j9kC1ibiiiho",
        "Ui9n4yGUnIPM",
        "KNrYcBq75EVy",
        "9MEVhzSIIO4W",
        "91btC-YUB6no",
        "pDH8xWPSU_1X"
      ],
      "authorship_tag": "ABX9TyMjUC55ykiruYKREhUKxuz+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oleonn/DataMining/blob/main/Data_mining_INaturalist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup (should be executed on startup)"
      ],
      "metadata": {
        "id": "xKjUNPrd0NWJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup and connection to Google Drive"
      ],
      "metadata": {
        "id": "na98opxzi3CS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXMzNMQsiX4w",
        "outputId": "620377a5-2ca2-4e7e-adc4-6c2f6bf8cb4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyinaturalist\n",
            "  Downloading pyinaturalist-0.19.0-py3-none-any.whl (143 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/143.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m143.4/143.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.7/143.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.10/dist-packages (from pyinaturalist) (23.2.0)\n",
            "Requirement already satisfied: keyring>=22.3 in /usr/lib/python3/dist-packages (from pyinaturalist) (23.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=3.0 in /usr/local/lib/python3.10/dist-packages (from pyinaturalist) (3.0.0)\n",
            "Requirement already satisfied: platformdirs>=2.6 in /usr/local/lib/python3.10/dist-packages (from pyinaturalist) (4.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.0 in /usr/local/lib/python3.10/dist-packages (from pyinaturalist) (2.8.2)\n",
            "Collecting python-forge>=18.6 (from pyinaturalist)\n",
            "  Downloading python_forge-18.6.0-py35-none-any.whl (31 kB)\n",
            "Requirement already satisfied: requests>=2.25 in /usr/local/lib/python3.10/dist-packages (from pyinaturalist) (2.31.0)\n",
            "Collecting requests-cache>=1.1 (from pyinaturalist)\n",
            "  Downloading requests_cache-1.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/61.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-ratelimiter>=0.3.2 (from pyinaturalist)\n",
            "  Downloading requests_ratelimiter-0.6.0-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: rich>=10.9 in /usr/local/lib/python3.10/dist-packages (from pyinaturalist) (13.7.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=3.0->pyinaturalist) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.0->pyinaturalist) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25->pyinaturalist) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25->pyinaturalist) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25->pyinaturalist) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25->pyinaturalist) (2024.6.2)\n",
            "Collecting cattrs>=22.2 (from requests-cache>=1.1->pyinaturalist)\n",
            "  Downloading cattrs-23.2.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting url-normalize>=1.4 (from requests-cache>=1.1->pyinaturalist)\n",
            "  Downloading url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB)\n",
            "Collecting pyrate-limiter<3.0 (from requests-ratelimiter>=0.3.2->pyinaturalist)\n",
            "  Downloading pyrate_limiter-2.10.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.9->pyinaturalist) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests-cache>=1.1->pyinaturalist) (1.2.1)\n",
            "Requirement already satisfied: typing-extensions!=4.6.3,>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests-cache>=1.1->pyinaturalist) (4.12.2)\n",
            "Installing collected packages: python-forge, url-normalize, pyrate-limiter, cattrs, requests-ratelimiter, requests-cache, pyinaturalist\n",
            "Successfully installed cattrs-23.2.3 pyinaturalist-0.19.0 pyrate-limiter-2.10.0 python-forge-18.6.0 requests-cache-1.2.1 requests-ratelimiter-0.6.0 url-normalize-1.4.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pyinaturalist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyinaturalist.v1.observations import get_observation_species_counts\n",
        "import json\n",
        "from pyinaturalist import (\n",
        "    Observation,\n",
        "    pprint,\n",
        "    get_observations,\n",
        "    get_observation_species_counts\n",
        ")\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import pandas as pd\n",
        "pd.options.display.max_colwidth = 100  #Sert a augmenter la qte de caracteres affiches pour chaque string\n",
        "import random\n",
        "\n",
        "import csv\n",
        "import requests\n",
        "import os\n",
        "import shutil"
      ],
      "metadata": {
        "id": "AP5191veiha4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8EY4OMWjAx_",
        "outputId": "67c2b0dd-5b51-4bc0-8f8f-d7197be5d757"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Directory and parameters"
      ],
      "metadata": {
        "id": "kfsXl1-PjSZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "directory = \"/content/drive/MyDrive/Projet_mellifere/Donnees/\"\n",
        "sp_classes = [\"Asclepias_syriaca\", \"Daucus_carota\", \"Eutrochium_maculatum\", \"Leucanthemum_vulgare\", \"Solidago_canadensis\"]\n",
        "originals = \"originals\"\n",
        "\n",
        "#Create class folders if they don't already exist in directory\n",
        "for name in sp_classes:\n",
        "  #Create the species folder\n",
        "  sp_classes_path = os.path.join(directory, name)\n",
        "  if not os.path.exists(sp_classes_path):\n",
        "    os.makedirs(sp_classes_path)\n",
        "    print(f\"folder {sp_classes_path} created.\")\n",
        "  #Create the originals subfolder\n",
        "  sp_classes_originals = os.path.join(sp_classes_path, originals)\n",
        "  if not os.path.exists(sp_classes_originals):\n",
        "    os.makedirs(sp_classes_originals)\n",
        "    print(f\"folder {sp_classes_originals} created.\")\n"
      ],
      "metadata": {
        "id": "XO4dJaovkMZi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before executing the next cell, export the occurences from the GBIF website for the targeted species. Make sure to select \"INaturalist (research)\" in the search filters. Download the occurences in Archive Darwin Core format. Open the zip file(s) and extract the \"multimedia.txt\" of every target species into their matching folder (in the species folder that is, not in the \"originals\" one)."
      ],
      "metadata": {
        "id": "deAZE5Dwjmy3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data mining"
      ],
      "metadata": {
        "id": "j9kC1ibiiiho"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data mining"
      ],
      "metadata": {
        "id": "Ui9n4yGUnIPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wished_format = \"small\" #either thumb, small, medium, original or large\"\n",
        "wished_nb = 2000 #total number of pictures wished for every species"
      ],
      "metadata": {
        "id": "9OZeu9PkN2Rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name in sp_classes:\n",
        "  #Creation of a random sample (n = wished_nb) from the list of pictures in the \"multimedia.txt\" file\n",
        "  sp_classes_path = os.path.join(directory, name)\n",
        "  img_list_complete = pd.read_csv(sp_classes_path+\"/multimedia.txt\", dtype=str, sep=\"\\t\")[\"identifier\"].tolist()\n",
        "  img_list_used = random.sample(img_list_complete, wished_nb)\n",
        "  for line in range(len(img_list_used)):\n",
        "    img_list_used[line] = img_list_used[line].replace(\"original\", wished_format)\n",
        "\n",
        "  #Import of all sampled pictures\n",
        "  sp_classes_originals = os.path.join(sp_classes_path, originals)\n",
        "  broken_images = []\n",
        "  count = 1\n",
        "  for img in img_list_used:\n",
        "    # We can split the file based on '/' and extract the last split within the Python list below:\n",
        "    file_name = img.split('/')[-2]\n",
        "    file_name = f\"{sp_classes_originals}/{file_name}.jpeg\"  # Update file extension to .jpeg\n",
        "    if count == 1:\n",
        "      print(f\"Download of {wished_nb} files for {name} has started in {sp_classes_originals}\")\n",
        "    if count % 100 == 0 and count < wished_nb:\n",
        "      print(f\"File {count} out of {wished_nb} for {name} has been downloaded in {sp_classes_originals}\")\n",
        "    if count == wished_nb:\n",
        "      print(f\"All {wished_nb} files for {name} have been downloaded in {sp_classes_originals}\")\n",
        "    count = count + 1\n",
        "    # Now let's send a request to the image URL:\n",
        "    r = requests.get(img, stream=True)\n",
        "    # We can check that the status code is 200 before doing anything else:\n",
        "    if r.status_code == 200:\n",
        "        # This command below will allow us to write the data to a file as binary:\n",
        "        with open(file_name, 'wb') as f:\n",
        "            for chunk in r.iter_content(1024):\n",
        "                f.write(chunk)\n",
        "    else:\n",
        "        # We will write all of the images back to the broken_images list:\n",
        "        broken_images.append(img)\n",
        "\n",
        "  with open(f\"{sp_classes_originals}/img_list_used_{name}.csv\", \"w\", newline=\"\") as f:\n",
        "    for item in img_list_used:\n",
        "      f.write(item + \",\\n\")\n",
        "    print(f\"Mission {name} complete.\")\n",
        "\n",
        "print(\"Mission complete. Good work, 007\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDOqj9SIrsav",
        "outputId": "31f69229-fc18-40ed-a3b7-fd406f2e8095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download of 2000 files for Asclepias_syriaca has started in /content/drive/MyDrive/Projet_mellifere/Donnees/Asclepias_syriaca/originals\n",
            "File 100 out of 2000 for Asclepias_syriaca has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Asclepias_syriaca/originals\n",
            "File 200 out of 2000 for Asclepias_syriaca has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Asclepias_syriaca/originals\n",
            "File 300 out of 2000 for Asclepias_syriaca has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Asclepias_syriaca/originals\n",
            "File 400 out of 2000 for Asclepias_syriaca has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Asclepias_syriaca/originals\n",
            "File 500 out of 2000 for Asclepias_syriaca has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Asclepias_syriaca/originals\n",
            "File 600 out of 2000 for Asclepias_syriaca has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Asclepias_syriaca/originals\n",
            "File 700 out of 2000 for Asclepias_syriaca has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Asclepias_syriaca/originals\n",
            "File 800 out of 2000 for Asclepias_syriaca has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Asclepias_syriaca/originals\n",
            "File 900 out of 2000 for Asclepias_syriaca has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Asclepias_syriaca/originals\n",
            "File 1000 out of 2000 for Asclepias_syriaca has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Asclepias_syriaca/originals\n",
            "File 1100 out of 2000 for Asclepias_syriaca has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Asclepias_syriaca/originals\n",
            "File 1200 out of 2000 for Asclepias_syriaca has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Asclepias_syriaca/originals\n",
            "File 1300 out of 2000 for Asclepias_syriaca has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Asclepias_syriaca/originals\n",
            "File 1400 out of 2000 for Asclepias_syriaca has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Asclepias_syriaca/originals\n",
            "File 1500 out of 2000 for Asclepias_syriaca has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Asclepias_syriaca/originals\n",
            "File 1600 out of 2000 for Asclepias_syriaca has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Asclepias_syriaca/originals\n",
            "File 1700 out of 2000 for Asclepias_syriaca has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Asclepias_syriaca/originals\n",
            "File 1800 out of 2000 for Asclepias_syriaca has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Asclepias_syriaca/originals\n",
            "File 1900 out of 2000 for Asclepias_syriaca has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Asclepias_syriaca/originals\n",
            "All 2000 files for Asclepias_syriaca have been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Asclepias_syriaca/originals\n",
            "Mission Asclepias_syriaca complete.\n",
            "Download of 2000 files for Daucus_carota has started in /content/drive/MyDrive/Projet_mellifere/Donnees/Daucus_carota/originals\n",
            "File 100 out of 2000 for Daucus_carota has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Daucus_carota/originals\n",
            "File 200 out of 2000 for Daucus_carota has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Daucus_carota/originals\n",
            "File 300 out of 2000 for Daucus_carota has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Daucus_carota/originals\n",
            "File 400 out of 2000 for Daucus_carota has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Daucus_carota/originals\n",
            "File 500 out of 2000 for Daucus_carota has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Daucus_carota/originals\n",
            "File 600 out of 2000 for Daucus_carota has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Daucus_carota/originals\n",
            "File 700 out of 2000 for Daucus_carota has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Daucus_carota/originals\n",
            "File 800 out of 2000 for Daucus_carota has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Daucus_carota/originals\n",
            "File 900 out of 2000 for Daucus_carota has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Daucus_carota/originals\n",
            "File 1000 out of 2000 for Daucus_carota has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Daucus_carota/originals\n",
            "File 1100 out of 2000 for Daucus_carota has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Daucus_carota/originals\n",
            "File 1200 out of 2000 for Daucus_carota has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Daucus_carota/originals\n",
            "File 1300 out of 2000 for Daucus_carota has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Daucus_carota/originals\n",
            "File 1400 out of 2000 for Daucus_carota has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Daucus_carota/originals\n",
            "File 1500 out of 2000 for Daucus_carota has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Daucus_carota/originals\n",
            "File 1600 out of 2000 for Daucus_carota has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Daucus_carota/originals\n",
            "File 1700 out of 2000 for Daucus_carota has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Daucus_carota/originals\n",
            "File 1800 out of 2000 for Daucus_carota has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Daucus_carota/originals\n",
            "File 1900 out of 2000 for Daucus_carota has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Daucus_carota/originals\n",
            "All 2000 files for Daucus_carota have been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Daucus_carota/originals\n",
            "Mission Daucus_carota complete.\n",
            "Download of 2000 files for Eutrochium_maculatum has started in /content/drive/MyDrive/Projet_mellifere/Donnees/Eutrochium_maculatum/originals\n",
            "File 100 out of 2000 for Eutrochium_maculatum has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Eutrochium_maculatum/originals\n",
            "File 200 out of 2000 for Eutrochium_maculatum has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Eutrochium_maculatum/originals\n",
            "File 300 out of 2000 for Eutrochium_maculatum has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Eutrochium_maculatum/originals\n",
            "File 400 out of 2000 for Eutrochium_maculatum has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Eutrochium_maculatum/originals\n",
            "File 500 out of 2000 for Eutrochium_maculatum has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Eutrochium_maculatum/originals\n",
            "File 600 out of 2000 for Eutrochium_maculatum has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Eutrochium_maculatum/originals\n",
            "File 700 out of 2000 for Eutrochium_maculatum has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Eutrochium_maculatum/originals\n",
            "File 800 out of 2000 for Eutrochium_maculatum has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Eutrochium_maculatum/originals\n",
            "File 900 out of 2000 for Eutrochium_maculatum has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Eutrochium_maculatum/originals\n",
            "File 1000 out of 2000 for Eutrochium_maculatum has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Eutrochium_maculatum/originals\n",
            "File 1100 out of 2000 for Eutrochium_maculatum has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Eutrochium_maculatum/originals\n",
            "File 1200 out of 2000 for Eutrochium_maculatum has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Eutrochium_maculatum/originals\n",
            "File 1300 out of 2000 for Eutrochium_maculatum has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Eutrochium_maculatum/originals\n",
            "File 1400 out of 2000 for Eutrochium_maculatum has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Eutrochium_maculatum/originals\n",
            "File 1500 out of 2000 for Eutrochium_maculatum has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Eutrochium_maculatum/originals\n",
            "File 1600 out of 2000 for Eutrochium_maculatum has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Eutrochium_maculatum/originals\n",
            "File 1700 out of 2000 for Eutrochium_maculatum has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Eutrochium_maculatum/originals\n",
            "File 1800 out of 2000 for Eutrochium_maculatum has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Eutrochium_maculatum/originals\n",
            "File 1900 out of 2000 for Eutrochium_maculatum has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Eutrochium_maculatum/originals\n",
            "All 2000 files for Eutrochium_maculatum have been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Eutrochium_maculatum/originals\n",
            "Mission Eutrochium_maculatum complete.\n",
            "Download of 2000 files for Leucanthemum_vulgare has started in /content/drive/MyDrive/Projet_mellifere/Donnees/Leucanthemum_vulgare/originals\n",
            "File 100 out of 2000 for Leucanthemum_vulgare has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Leucanthemum_vulgare/originals\n",
            "File 200 out of 2000 for Leucanthemum_vulgare has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Leucanthemum_vulgare/originals\n",
            "File 300 out of 2000 for Leucanthemum_vulgare has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Leucanthemum_vulgare/originals\n",
            "File 400 out of 2000 for Leucanthemum_vulgare has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Leucanthemum_vulgare/originals\n",
            "File 500 out of 2000 for Leucanthemum_vulgare has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Leucanthemum_vulgare/originals\n",
            "File 600 out of 2000 for Leucanthemum_vulgare has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Leucanthemum_vulgare/originals\n",
            "File 700 out of 2000 for Leucanthemum_vulgare has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Leucanthemum_vulgare/originals\n",
            "File 800 out of 2000 for Leucanthemum_vulgare has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Leucanthemum_vulgare/originals\n",
            "File 900 out of 2000 for Leucanthemum_vulgare has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Leucanthemum_vulgare/originals\n",
            "File 1000 out of 2000 for Leucanthemum_vulgare has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Leucanthemum_vulgare/originals\n",
            "File 1100 out of 2000 for Leucanthemum_vulgare has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Leucanthemum_vulgare/originals\n",
            "File 1200 out of 2000 for Leucanthemum_vulgare has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Leucanthemum_vulgare/originals\n",
            "File 1300 out of 2000 for Leucanthemum_vulgare has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Leucanthemum_vulgare/originals\n",
            "File 1400 out of 2000 for Leucanthemum_vulgare has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Leucanthemum_vulgare/originals\n",
            "File 1500 out of 2000 for Leucanthemum_vulgare has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Leucanthemum_vulgare/originals\n",
            "File 1600 out of 2000 for Leucanthemum_vulgare has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Leucanthemum_vulgare/originals\n",
            "File 1700 out of 2000 for Leucanthemum_vulgare has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Leucanthemum_vulgare/originals\n",
            "File 1800 out of 2000 for Leucanthemum_vulgare has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Leucanthemum_vulgare/originals\n",
            "File 1900 out of 2000 for Leucanthemum_vulgare has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Leucanthemum_vulgare/originals\n",
            "All 2000 files for Leucanthemum_vulgare have been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Leucanthemum_vulgare/originals\n",
            "Mission Leucanthemum_vulgare complete.\n",
            "Download of 2000 files for Solidago_canadensis has started in /content/drive/MyDrive/Projet_mellifere/Donnees/Solidago_canadensis/originals\n",
            "File 100 out of 2000 for Solidago_canadensis has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Solidago_canadensis/originals\n",
            "File 200 out of 2000 for Solidago_canadensis has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Solidago_canadensis/originals\n",
            "File 300 out of 2000 for Solidago_canadensis has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Solidago_canadensis/originals\n",
            "File 400 out of 2000 for Solidago_canadensis has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Solidago_canadensis/originals\n",
            "File 500 out of 2000 for Solidago_canadensis has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Solidago_canadensis/originals\n",
            "File 600 out of 2000 for Solidago_canadensis has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Solidago_canadensis/originals\n",
            "File 700 out of 2000 for Solidago_canadensis has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Solidago_canadensis/originals\n",
            "File 800 out of 2000 for Solidago_canadensis has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Solidago_canadensis/originals\n",
            "File 900 out of 2000 for Solidago_canadensis has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Solidago_canadensis/originals\n",
            "File 1000 out of 2000 for Solidago_canadensis has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Solidago_canadensis/originals\n",
            "File 1100 out of 2000 for Solidago_canadensis has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Solidago_canadensis/originals\n",
            "File 1200 out of 2000 for Solidago_canadensis has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Solidago_canadensis/originals\n",
            "File 1300 out of 2000 for Solidago_canadensis has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Solidago_canadensis/originals\n",
            "File 1400 out of 2000 for Solidago_canadensis has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Solidago_canadensis/originals\n",
            "File 1500 out of 2000 for Solidago_canadensis has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Solidago_canadensis/originals\n",
            "File 1600 out of 2000 for Solidago_canadensis has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Solidago_canadensis/originals\n",
            "File 1700 out of 2000 for Solidago_canadensis has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Solidago_canadensis/originals\n",
            "File 1800 out of 2000 for Solidago_canadensis has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Solidago_canadensis/originals\n",
            "File 1900 out of 2000 for Solidago_canadensis has been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Solidago_canadensis/originals\n",
            "All 2000 files for Solidago_canadensis have been downloaded in /content/drive/MyDrive/Projet_mellifere/Donnees/Solidago_canadensis/originals\n",
            "Mission Solidago_canadensis complete.\n",
            "Mission complete. Good work, 007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Image size validation"
      ],
      "metadata": {
        "id": "KNrYcBq75EVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking if every image has at least 128 pixels of width and height, and deletion of those that don't\n",
        "def size_check():\n",
        "  for name in sp_classes:\n",
        "    sp_classes_path = os.path.join(directory, name)\n",
        "    sp_classes_originals = os.path.join(sp_classes_path, originals)\n",
        "\n",
        "    for filename in os.listdir(sp_classes_originals):\n",
        "      if filename.endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
        "        img_path = os.path.join(sp_classes_originals, filename)\n",
        "        img = Image.open(img_path)\n",
        "        width, height = img.size\n",
        "\n",
        "        if width < 128 or height < 128:\n",
        "          print(f\"{img_path} is too small (w {width} x h {height}) and has been deleted\")\n",
        "          os.remove(img_path)\n",
        "\n",
        "    print(f\"{name} checked with no mo' undersized images to declare!\")\n",
        "  print(\"Mission complete! 10-4\")\n",
        "\n",
        "\n",
        "#Checking if images have been deleted, and download of additional pictures if it's the case\n",
        "def redownload():\n",
        "  for name in sp_classes:\n",
        "    sp_classes_path = os.path.join(directory, name)\n",
        "    sp_classes_originals = os.path.join(sp_classes_path, originals)\n",
        "\n",
        "    img_list = []\n",
        "    for filename in os.listdir(sp_classes_originals):\n",
        "      if filename.endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
        "        img_list.append(filename)\n",
        "    print(f\"Number of images for {name} : {len(img_list)} out of {wished_nb} expected\")\n",
        "\n",
        "    if len(img_list) < wished_nb: #If a redownload is necessary\n",
        "      compensation = wished_nb - len(img_list)\n",
        "      img_list_used_csv = f\"{sp_classes_originals}/img_list_used_{name}.csv\"\n",
        "      #Reading the CSV file\n",
        "      with open(img_list_used_csv, \"r\") as f:\n",
        "        reader = csv.reader(f)\n",
        "        used_items = [row[0] for row in reader]\n",
        "        for line in range(len(used_items)): #Replace the wished format for the \"original\" format in the links of the used_items list. Makes comparison with the img_list_complete possible\n",
        "          used_items[line] = used_items[line].replace(wished_format, \"original\")\n",
        "\n",
        "      #Creation of a random sample (n = compensation) from the list of pictures (only the unused) in the \"multimedia.txt\" file\n",
        "      img_list_complete = pd.read_csv(sp_classes_path+\"/multimedia.txt\", dtype=str, sep=\"\\t\")[\"identifier\"].tolist()\n",
        "      unused_items = [item for item in img_list_complete if item not in used_items] #Finding unused items\n",
        "      #Additional selection\n",
        "      new_items = random.sample(unused_items, compensation)\n",
        "      for line in range(len(new_items)): #Replace the wished format for the \"original\" format in the links of the used_items list. Makes comparison with the img_list_complete possible\n",
        "        new_items[line] = new_items[line].replace(\"original\", wished_format)\n",
        "      #Appending to CSV (updating the .csv file to inclued newly selected items)\n",
        "      with open(img_list_used_csv, \"a\", newline=\"\") as f:\n",
        "        for item in new_items:\n",
        "          f.write(item + \",\\n\")\n",
        "\n",
        "      #Downloading the newly sampled images\n",
        "      broken_images = []\n",
        "      count = 1\n",
        "      for img in new_items:\n",
        "        # We can split the file based on '/' and extract the last split within the Python list below:\n",
        "        file_name = img.split('/')[-2]\n",
        "        file_name = f\"{sp_classes_originals}/{file_name}.jpeg\"  # Update file extension to .jpeg\n",
        "        if count == 1:\n",
        "          print(f\"Download of {compensation} files for {name} has started in {sp_classes_originals}\")\n",
        "        if count % 10 == 0 and count < compensation:\n",
        "          print(f\"File {count} out of {compensation} for {name} has been downloaded in {sp_classes_originals}\")\n",
        "        if count == compensation:\n",
        "          print(f\"All {compensation} additional files for {name} have been downloaded in {sp_classes_originals}\")\n",
        "        count = count + 1\n",
        "        # Now let's send a request to the image URL:\n",
        "        r = requests.get(img, stream=True)\n",
        "        # We can check that the status code is 200 before doing anything else:\n",
        "        if r.status_code == 200:\n",
        "            # This command below will allow us to write the data to a file as binary:\n",
        "            with open(file_name, 'wb') as f:\n",
        "                for chunk in r.iter_content(1024):\n",
        "                    f.write(chunk)\n",
        "        else:\n",
        "            # We will write all of the images back to the broken_images list:\n",
        "            broken_images.append(img)"
      ],
      "metadata": {
        "id": "Y4CxABYI5MLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternate between the two following cells to\n",
        "1) check the size of every picture and delete those that are under 128pixels of width and height\n",
        "2) redownload pictures to replace the deleted ones with new, newly sampled and so far unused pictures\n",
        "Make sure the Google Drive has had time to synch (it may take up to 10 seconds) after each redownload"
      ],
      "metadata": {
        "id": "Xx52d371Ql6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "size_check()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcm5jiktFe25",
        "outputId": "d93f002a-b0a2-4b6c-f8b5-882f0937c6b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asclepias_syriaca checked with no mo' undersized images to declare!\n",
            "Daucus_carota checked with no mo' undersized images to declare!\n",
            "Eutrochium_maculatum checked with no mo' undersized images to declare!\n",
            "Leucanthemum_vulgare checked with no mo' undersized images to declare!\n",
            "Solidago_canadensis checked with no mo' undersized images to declare!\n",
            "Mission complete! 10-4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "redownload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpNXYE52LGwg",
        "outputId": "6ccdcc22-dfbd-40f4-fd81-ac170fc5c4c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images for Asclepias_syriaca : 2000 out of 2000 expected\n",
            "Number of images for Daucus_carota : 2000 out of 2000 expected\n",
            "Number of images for Eutrochium_maculatum : 2000 out of 2000 expected\n",
            "Number of images for Leucanthemum_vulgare : 2000 out of 2000 expected\n",
            "Number of images for Solidago_canadensis : 2000 out of 2000 expected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cropping"
      ],
      "metadata": {
        "id": "CWP1_6yfRON2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Centered 128px square"
      ],
      "metadata": {
        "id": "9MEVhzSIIO4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "center_cropped = \"center_cropped\"\n",
        "\n",
        "for name in sp_classes:\n",
        "  #Create the center cropped subfolder\n",
        "  sp_classes_path = os.path.join(directory, name)\n",
        "  sp_classes_originals = os.path.join(sp_classes_path, originals)\n",
        "  sp_classes_cropped = os.path.join(sp_classes_path, center_cropped)\n",
        "  if not os.path.exists(sp_classes_cropped):\n",
        "      os.makedirs(sp_classes_cropped)\n",
        "      print(f\"folder {sp_classes_cropped} created.\")\n",
        "\n",
        "  #Center crop\n",
        "  print(f\"Cropping of {name} images has started. Data will be saved in {sp_classes_cropped}\")\n",
        "  for filename in os.listdir(sp_classes_originals):\n",
        "    if filename.endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
        "      img_path = os.path.join(sp_classes_originals, filename)\n",
        "      img = Image.open(img_path)\n",
        "      width, height = img.size\n",
        "      #Setting where to crop\n",
        "      left = (width-128)/2 + ((width-128)/2)%1 #The modulo section here make it so that the answer is always a whole number\n",
        "      right = left +128\n",
        "      top = (height-128)/2 + ((height-128)/2)%1\n",
        "      bottom = top +128\n",
        "      #Crop and save in center_cropped folder\n",
        "      img_cropped = img.crop((left,top,right,bottom))\n",
        "      #Convert the image to RGB mode before saving as JPEG\n",
        "      img_cropped = img_cropped.convert('RGB')\n",
        "      file_name_cropped = f\"{sp_classes_cropped}/{filename}\"\n",
        "      img_cropped.save(file_name_cropped)\n",
        "  print(f\"{name} images have been cropped to 128x128px and saved in {sp_classes_cropped}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLxj2ZXbRRLh",
        "outputId": "0fb607f3-cc63-4278-b116-b7d73449edfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "folder /content/drive/MyDrive/Projet_mellifere/Donnees/Asclepias_syriaca/center_cropped created.\n",
            "Cropping of Asclepias_syriaca images has started. Data will be saved in /content/drive/MyDrive/Projet_mellifere/Donnees/Asclepias_syriaca/center_cropped\n",
            "Asclepias_syriaca images have been cropped to 128x128px and saved in /content/drive/MyDrive/Projet_mellifere/Donnees/Asclepias_syriaca/center_cropped\n",
            "folder /content/drive/MyDrive/Projet_mellifere/Donnees/Daucus_carota/center_cropped created.\n",
            "Cropping of Daucus_carota images has started. Data will be saved in /content/drive/MyDrive/Projet_mellifere/Donnees/Daucus_carota/center_cropped\n",
            "Daucus_carota images have been cropped to 128x128px and saved in /content/drive/MyDrive/Projet_mellifere/Donnees/Daucus_carota/center_cropped\n",
            "folder /content/drive/MyDrive/Projet_mellifere/Donnees/Eutrochium_maculatum/center_cropped created.\n",
            "Cropping of Eutrochium_maculatum images has started. Data will be saved in /content/drive/MyDrive/Projet_mellifere/Donnees/Eutrochium_maculatum/center_cropped\n",
            "Eutrochium_maculatum images have been cropped to 128x128px and saved in /content/drive/MyDrive/Projet_mellifere/Donnees/Eutrochium_maculatum/center_cropped\n",
            "folder /content/drive/MyDrive/Projet_mellifere/Donnees/Leucanthemum_vulgare/center_cropped created.\n",
            "Cropping of Leucanthemum_vulgare images has started. Data will be saved in /content/drive/MyDrive/Projet_mellifere/Donnees/Leucanthemum_vulgare/center_cropped\n",
            "Leucanthemum_vulgare images have been cropped to 128x128px and saved in /content/drive/MyDrive/Projet_mellifere/Donnees/Leucanthemum_vulgare/center_cropped\n",
            "folder /content/drive/MyDrive/Projet_mellifere/Donnees/Solidago_canadensis/center_cropped created.\n",
            "Cropping of Solidago_canadensis images has started. Data will be saved in /content/drive/MyDrive/Projet_mellifere/Donnees/Solidago_canadensis/center_cropped\n",
            "Solidago_canadensis images have been cropped to 128x128px and saved in /content/drive/MyDrive/Projet_mellifere/Donnees/Solidago_canadensis/center_cropped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Resized so that shortest side=128 px, and cropped to 128x128\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "91btC-YUB6no"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resized_cropped = \"resized_cropped\"\n",
        "\n",
        "for name in sp_classes:\n",
        "  #Create the center cropped subfolder\n",
        "  sp_classes_path = os.path.join(directory, name)\n",
        "  sp_classes_originals = os.path.join(sp_classes_path, originals)\n",
        "  sp_classes_cropped = os.path.join(sp_classes_path, resized_cropped)\n",
        "  if not os.path.exists(sp_classes_cropped):\n",
        "      os.makedirs(sp_classes_cropped)\n",
        "      print(f\"folder {sp_classes_cropped} created.\")\n",
        "\n",
        "  #Resizing and cropping\n",
        "  print(f\"Cropping of {name} images has started. Data will be saved in {sp_classes_cropped}\")\n",
        "  for filename in os.listdir(sp_classes_originals):\n",
        "    if filename.endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
        "      img_path = os.path.join(sp_classes_originals, filename)\n",
        "      img = Image.open(img_path)\n",
        "      width, height = img.size\n",
        "      #Resize to shortest size = 128\n",
        "      if width < height:\n",
        "        ratio = 128/width\n",
        "        new_width = 128\n",
        "        new_height = int(height*ratio)\n",
        "      else:\n",
        "        ratio = 128/height\n",
        "        new_width = int(width*ratio)\n",
        "        new_height = 128\n",
        "      resized_img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
        "\n",
        "      #Setting where to crop\n",
        "      width, height = resized_img.size\n",
        "      left = (width-128)/2 + ((width-128)/2)%1 #The modulo section here make it so that the answer is always a whole number\n",
        "      right = left +128\n",
        "      top = (height-128)/2 + ((height-128)/2)%1\n",
        "      bottom = top +128\n",
        "      #Crop and save in center_cropped folder\n",
        "      img_cropped = resized_img.crop((left,top,right,bottom))\n",
        "      #Convert the image to RGB mode before saving as JPEG\n",
        "      img_cropped = img_cropped.convert('RGB')\n",
        "      file_name_cropped = f\"{sp_classes_cropped}/{filename}\"\n",
        "      img_cropped.save(file_name_cropped)\n",
        "  print(f\"{name} images have been cropped to 128x128px and saved in {sp_classes_cropped}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWGH5flNB5l0",
        "outputId": "0379be9c-99f9-4fa1-94bb-b58f5cb680e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "folder /content/drive/MyDrive/Projet_mellifere/Donnees/Asclepias_syriaca/resized_cropped created.\n",
            "Cropping of Asclepias_syriaca images has started. Data will be saved in /content/drive/MyDrive/Projet_mellifere/Donnees/Asclepias_syriaca/resized_cropped\n",
            "Asclepias_syriaca images have been cropped to 128x128px and saved in /content/drive/MyDrive/Projet_mellifere/Donnees/Asclepias_syriaca/resized_cropped\n",
            "folder /content/drive/MyDrive/Projet_mellifere/Donnees/Daucus_carota/resized_cropped created.\n",
            "Cropping of Daucus_carota images has started. Data will be saved in /content/drive/MyDrive/Projet_mellifere/Donnees/Daucus_carota/resized_cropped\n",
            "Daucus_carota images have been cropped to 128x128px and saved in /content/drive/MyDrive/Projet_mellifere/Donnees/Daucus_carota/resized_cropped\n",
            "folder /content/drive/MyDrive/Projet_mellifere/Donnees/Eutrochium_maculatum/resized_cropped created.\n",
            "Cropping of Eutrochium_maculatum images has started. Data will be saved in /content/drive/MyDrive/Projet_mellifere/Donnees/Eutrochium_maculatum/resized_cropped\n",
            "Eutrochium_maculatum images have been cropped to 128x128px and saved in /content/drive/MyDrive/Projet_mellifere/Donnees/Eutrochium_maculatum/resized_cropped\n",
            "folder /content/drive/MyDrive/Projet_mellifere/Donnees/Leucanthemum_vulgare/resized_cropped created.\n",
            "Cropping of Leucanthemum_vulgare images has started. Data will be saved in /content/drive/MyDrive/Projet_mellifere/Donnees/Leucanthemum_vulgare/resized_cropped\n",
            "Leucanthemum_vulgare images have been cropped to 128x128px and saved in /content/drive/MyDrive/Projet_mellifere/Donnees/Leucanthemum_vulgare/resized_cropped\n",
            "folder /content/drive/MyDrive/Projet_mellifere/Donnees/Solidago_canadensis/resized_cropped created.\n",
            "Cropping of Solidago_canadensis images has started. Data will be saved in /content/drive/MyDrive/Projet_mellifere/Donnees/Solidago_canadensis/resized_cropped\n",
            "Solidago_canadensis images have been cropped to 128x128px and saved in /content/drive/MyDrive/Projet_mellifere/Donnees/Solidago_canadensis/resized_cropped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WK_lqlDYYubS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data split"
      ],
      "metadata": {
        "id": "pDH8xWPSU_1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = \"/content/drive/MyDrive/Projet_mellifere/Modeles/INat_resized-cropped\"\n",
        "data_folder = \"resized_cropped\"\n",
        "train_data = 60\n",
        "valid_data = 20\n",
        "test_data = 20\n",
        "\n",
        "if not os.path.exists(model_dir):\n",
        "  os.makedirs(model_dir)\n",
        "  print(f\"folder {model_dir} created.\")"
      ],
      "metadata": {
        "id": "vRIwmyoQbZEp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if Google Drive has synced properly (that is, check if the newly created folder appears on the Drive)"
      ],
      "metadata": {
        "id": "BlnY7E1210_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the target training, validation and test folders\n",
        "train_path = f\"{model_dir}/training_data\"\n",
        "if not os.path.exists(train_path):\n",
        "  os.makedirs(train_path)\n",
        "  print(f\"folder {train_path} created.\")\n",
        "\n",
        "valid_path = f\"{model_dir}/validation_data\"\n",
        "if not os.path.exists(valid_path):\n",
        "  os.makedirs(valid_path)\n",
        "  print(f\"folder {valid_path} created.\")\n",
        "\n",
        "test_path = f\"{model_dir}/test_data\"\n",
        "if not os.path.exists(test_path):\n",
        "  os.makedirs(test_path)\n",
        "  print(f\"folder {test_path} created.\")"
      ],
      "metadata": {
        "id": "KtlTKTOr1k5S"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if Google Drive has synced properly (that is, check if the newly created folder appears on the Drive)"
      ],
      "metadata": {
        "id": "YrmjZaMu2G_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name in sp_classes:\n",
        "  #Create the class folders inside train_path, valid_path and test_path\n",
        "  train_path_sp = os.path.join(train_path, name)\n",
        "  if not os.path.exists(train_path_sp):\n",
        "    os.makedirs(train_path_sp)\n",
        "    print(f\"folder {train_path_sp} created.\")\n",
        "\n",
        "  valid_path_sp = os.path.join(valid_path, name)\n",
        "  if not os.path.exists(valid_path_sp):\n",
        "    os.makedirs(valid_path_sp)\n",
        "    print(f\"folder {valid_path_sp} created.\")\n",
        "\n",
        "  test_path_sp = os.path.join(test_path, name)\n",
        "  if not os.path.exists(test_path_sp):\n",
        "    os.makedirs(test_path_sp)\n",
        "    print(f\"folder {test_path_sp} created.\")"
      ],
      "metadata": {
        "id": "GI4Q7iUm1zD1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if Google Drive has synced properly (that is, check if the newly created folder appears on the Drive)"
      ],
      "metadata": {
        "id": "yp7CByor2INb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_split(name, model_dir, data_folder, train_data, vali_data, test_data):\n",
        "\n",
        "  #name : species_name as seen in sp_classes\n",
        "  #model_dir : path to the model directory\n",
        "  #data_folder : for every class, which folder to use (ex. resized_cropped)\n",
        "  #train_data : percentage of training data (ex. 60)\n",
        "  #valid_data : percentage of validation data (ex. 20)\n",
        "  #test_data : percentage of test data (ex. 20)\n",
        "\n",
        "  total = train_data + valid_data + test_data\n",
        "  if total != 100:\n",
        "    raise ValueError(\"The sum of training, validation and test percentages must be equal to 100\")\n",
        "\n",
        "  else:\n",
        "  #Split the data in the right folders in the right proportions\n",
        "    print(f\"Proceeding with {name}\")\n",
        "    data_path = os.path.join(directory, name, data_folder)\n",
        "    data_list = [f for f in os.listdir(data_path) if f.endswith(\".jpeg\")] #lists all .jpeg files in the data_path folder\n",
        "    #Create the class folders inside train_path, valid_path and test_path\n",
        "    train_path_sp = os.path.join(train_path, name)\n",
        "    valid_path_sp = os.path.join(valid_path, name)\n",
        "    test_path_sp = os.path.join(test_path, name)\n",
        "\n",
        "    #Set up the proportions\n",
        "    train_nb = int(train_data/100*len(data_list))\n",
        "    if train_nb % 1 != 0 and train_nb % 1 < 0.5:\n",
        "      train_nb = int(train_data/100*len(data_list) - train_data/100*len(data_list)%1)\n",
        "    if train_nb %1 >= 0.5:\n",
        "      train_nb = int(train_data/100*len(data_list) +1 - train_data/100*len(data_list)%1)\n",
        "\n",
        "    valid_nb = int(valid_data/100*len(data_list))\n",
        "    if valid_nb % 1 != 0 and valid_nb % 1 < 0.5:\n",
        "      valid_nb = int(valid_data/100*len(data_list) - valid_data/100*len(data_list)%1)\n",
        "    if valid_nb %1 >= 0.5:\n",
        "      valid_nb = int(valid_data/100*len(data_list) +1 - valid_data/100*len(data_list)%1)\n",
        "\n",
        "    test_nb = int(len(data_list) - train_nb - valid_nb)\n",
        "\n",
        "    #Split the list\n",
        "    random.shuffle(data_list)\n",
        "    train_list = data_list[:train_nb]\n",
        "    valid_list = data_list[train_nb: train_nb + valid_nb]\n",
        "    test_list = data_list[train_nb + valid_nb:]\n",
        "\n",
        "    #Copy train_list files and save them in train_path_sp\n",
        "    for filename in train_list:\n",
        "      file_path = os.path.join(data_path, filename)\n",
        "      destination_path = os.path.join(train_path_sp, filename)\n",
        "      shutil.copyfile(file_path, destination_path)\n",
        "    print(f\"{train_nb} files from {name} have been transfered to {train_path_sp}\")\n",
        "\n",
        "    #Copy valid_list files and save them in valid_path_sp\n",
        "    for filename in valid_list:\n",
        "      file_path = os.path.join(data_path, filename)\n",
        "      destination_path = os.path.join(valid_path_sp, filename)\n",
        "      shutil.copyfile(file_path, destination_path)\n",
        "    print(f\"{valid_nb} files from {name} have been transfered to {valid_path_sp}\")\n",
        "\n",
        "    #Copy test_list files and save them in test_path_sp\n",
        "    for filename in test_list:\n",
        "      file_path = os.path.join(data_path, filename)\n",
        "      destination_path = os.path.join(test_path_sp, filename)\n",
        "      shutil.copyfile(file_path, destination_path)\n",
        "    print(f\"{test_nb} files from {name} have been transfered to {test_path_sp}\")\n",
        "\n",
        "print(\"Mission complete. Good job, 007.\")"
      ],
      "metadata": {
        "id": "ysEZNSmRVCDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2673042-9d3b-4c8d-f419-cf90ed16e786"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mission complete. Good job, 007.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute the following function one species at a time (by changing the selected item from sp_classes until it matches the length of sp_classes)\n",
        "Leave enough time between every species for Google Drive to update and sync (the test_data folder of the previous species should be fully updated before executing further)"
      ],
      "metadata": {
        "id": "GLwOhvkakeTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name = sp_classes[4]\n",
        "data_split(name, model_dir, data_folder, train_data, valid_data, test_data)"
      ],
      "metadata": {
        "id": "Sq2noc5Sw-uw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
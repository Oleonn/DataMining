{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "hQnMqjX7UFyf",
        "dq-C9dZ1Ud6P",
        "pDH8xWPSU_1X",
        "uk02x9-ZrdxJ",
        "m83NjYNKrvRa",
        "74zvx9DztXlI",
        "I4zbLRshtXlP"
      ],
      "authorship_tag": "ABX9TyOO0PNdGWgBGjtNW93FXv0b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oleonn/DataMining/blob/main/INat_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup (should be executed on startup)"
      ],
      "metadata": {
        "id": "hQnMqjX7UFyf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup and connection to Google Drive"
      ],
      "metadata": {
        "id": "dq-C9dZ1Ud6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D"
      ],
      "metadata": {
        "id": "RulJNSTWUIz9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "APiWWH5NUcwp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1992b5d9-84a2-4a8b-b045-edd6ed280b4d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Directories"
      ],
      "metadata": {
        "id": "pDH8xWPSU_1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/drive/MyDrive/Projet_mellifere/Modeles/INat_resized-cropped\" #where to find the training, validation and test data\n",
        "train_path = os.path.join(data_dir, \"training_data\")\n",
        "valid_path = os.path.join(data_dir, \"validation_data\")\n",
        "test_path = os.path.join(data_dir, \"test_data\")\n",
        "sp_classes = [\"Asclepias_syriaca\", \"Daucus_carota\", \"Eutrochium_maculatum\", \"Leucanthemum_vulgare\", \"Solidago_canadensis\"] #list of classes"
      ],
      "metadata": {
        "id": "ehFO9t2SYINj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ResNet50V2 CNN"
      ],
      "metadata": {
        "id": "igURTEM1nb_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##All base model's layers are frozen, and only the new layers are trainable"
      ],
      "metadata": {
        "id": "uk02x9-ZrdxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "CCS_iIVInfR8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = ResNet50V2(weights=\"imagenet\", include_top=False, input_shape = (128, 128, 3)) #That is, 128x123 pixels over 3 channels (RGB)\n",
        "\n",
        "#Freezing the base_model'S layers\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "#Adding custom layers on top\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(64, activation = \"relu\"))\n",
        "model.add(Dense(len(sp_classes), activation=\"softmax\")) #The model finishes with a number of outputs equal to the number of classes in sp_classes\n",
        "\n",
        "#Compiling the model\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "wxDLxmh0nlF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing training, validation and test data"
      ],
      "metadata": {
        "id": "TWe0Om6m1GJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_batch_size = 32\n",
        "valid_batch_size = 32\n",
        "test_batch_size = 32\n",
        "\n",
        "#Training data\n",
        "print(\"For training data...\")\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255, # Rescale pixel values between 0 and 1\n",
        "    horizontal_flip=True, # Randomly flip images horizontally\n",
        "    vertical_flip=True, #Randomly flip images vertically\n",
        ")\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    batch_size=train_batch_size, # Set batch size\n",
        "    class_mode='categorical' # Use categorical labels for multi-class classification\n",
        ")\n",
        "\n",
        "#Validation data\n",
        "print(\"For validation data...\")\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255) # Only rescale for validation data\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    valid_path,\n",
        "    batch_size=valid_batch_size, # Set batch size\n",
        "    class_mode='categorical' # Use categorical labels for multi-class classification\n",
        ")\n",
        "\n",
        "#Test data\n",
        "print(\"For test data...\")\n",
        "test_datagen = ImageDataGenerator(rescale=1./255) # Only rescale for test data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    batch_size=test_batch_size, # Set batch size\n",
        "    class_mode='categorical' # Use categorical labels for multi-class classification\n",
        ")"
      ],
      "metadata": {
        "id": "JFSsyejh1Fnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = os.path.join(data_dir, \"ResNet50V2_base-model-frzn.keras\")\n",
        "checkpoint = ModelCheckpoint(model_path, monitor = \"val_accuracy\", verbose=2, save_best_only=True, mode=\"max\") #The model will be saved every time an epoch shows an improvement in accuracy\n",
        "early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience=4, verbose=2, mode=\"max\")\n",
        "\n",
        "#Fit the model to the training data\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=60,\n",
        "    validation_data = valid_generator,\n",
        "    callbacks=[checkpoint, early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "CIGEMXeax0Km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Don't forget to copy the previous training log to monitor the evolution of the accuracy across all epochs"
      ],
      "metadata": {
        "id": "xD9Rg3BidM9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model's performance\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"The tested accuracy is {test_accuracy} and the tested loss is {test_loss}\")"
      ],
      "metadata": {
        "id": "jUaZDk-Az1wE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Only the base model's first 2 layers are frozen, and the rest is trainable"
      ],
      "metadata": {
        "id": "m83NjYNKrvRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "82sg3kbBrvRa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = ResNet50V2(weights=\"imagenet\", include_top=False, input_shape = (128, 128, 3)) #That is, 128x123 pixels over 3 channels (RGB)\n",
        "\n",
        "#Freezing the first 2 layers\n",
        "for layer in base_model.layers[:2]:\n",
        "  layer.trainable = False\n",
        "\n",
        "#Adding custom layers on top\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(64, activation = \"relu\"))\n",
        "model.add(Dense(len(sp_classes), activation=\"softmax\")) #The model finishes with a number of outputs equal to the number of classes in sp_classes\n",
        "\n",
        "#Compiling the model\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "mKlfmdcgrvRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing training, validation and test data"
      ],
      "metadata": {
        "id": "XNhlt1RDrvRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_batch_size = 32\n",
        "valid_batch_size = 32\n",
        "test_batch_size = 32\n",
        "\n",
        "#Training data\n",
        "print(\"For training data...\")\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255, # Rescale pixel values between 0 and 1\n",
        "    horizontal_flip=True, # Randomly flip images horizontally\n",
        "    vertical_flip=True, #Randomly flip images vertically\n",
        ")\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    batch_size=train_batch_size, # Set batch size\n",
        "    class_mode='categorical' # Use categorical labels for multi-class classification\n",
        ")\n",
        "\n",
        "#Validation data\n",
        "print(\"For validation data...\")\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255) # Only rescale for validation data\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    valid_path,\n",
        "    batch_size=valid_batch_size, # Set batch size\n",
        "    class_mode='categorical' # Use categorical labels for multi-class classification\n",
        ")\n",
        "\n",
        "#Test data\n",
        "print(\"For test data...\")\n",
        "test_datagen = ImageDataGenerator(rescale=1./255) # Only rescale for test data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    batch_size=test_batch_size, # Set batch size\n",
        "    class_mode='categorical' # Use categorical labels for multi-class classification\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e791442c-fe38-48a1-ca6e-72e10f8b3a26",
        "id": "lhyH4DqorvRb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For training data...\n",
            "Found 6000 images belonging to 5 classes.\n",
            "For validation data...\n",
            "Found 2000 images belonging to 5 classes.\n",
            "For test data...\n",
            "Found 2000 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = os.path.join(data_dir, \"ResNet50V2_2-bottom-layers-frzn.keras\")\n",
        "checkpoint = ModelCheckpoint(model_path, monitor = \"val_accuracy\", verbose=2, save_best_only=True, mode=\"max\") #The model will be saved every time an epoch shows an improvement in accuracy\n",
        "early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience=4, verbose=2, mode=\"max\")\n",
        "\n",
        "#Fit the model to the training data\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=60,\n",
        "    validation_data = valid_generator,\n",
        "    callbacks=[checkpoint, early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8f5796f-eadc-4244-f04e-179062f7665d",
        "id": "UxxQPCM2rvRb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "188/188 [==============================] - ETA: 0s - loss: 1.6084 - accuracy: 0.2497\n",
            "Epoch 1: val_accuracy improved from -inf to 0.31500, saving model to best_model.keras\n",
            "188/188 [==============================] - 2019s 11s/step - loss: 1.6084 - accuracy: 0.2497 - val_loss: 1.5550 - val_accuracy: 0.3150\n",
            "Epoch 2/60\n",
            "188/188 [==============================] - ETA: 0s - loss: 1.5772 - accuracy: 0.2850\n",
            "Epoch 2: val_accuracy did not improve from 0.31500\n",
            "188/188 [==============================] - 2000s 11s/step - loss: 1.5772 - accuracy: 0.2850 - val_loss: 1.5704 - val_accuracy: 0.2610\n",
            "Epoch 3/60\n",
            "188/188 [==============================] - ETA: 0s - loss: 1.5449 - accuracy: 0.3077\n",
            "Epoch 3: val_accuracy improved from 0.31500 to 0.32800, saving model to best_model.keras\n",
            "188/188 [==============================] - 1982s 11s/step - loss: 1.5449 - accuracy: 0.3077 - val_loss: 1.5788 - val_accuracy: 0.3280\n",
            "Epoch 4/60\n",
            "188/188 [==============================] - ETA: 0s - loss: 1.5213 - accuracy: 0.3255\n",
            "Epoch 4: val_accuracy improved from 0.32800 to 0.36250, saving model to best_model.keras\n",
            "188/188 [==============================] - 1995s 11s/step - loss: 1.5213 - accuracy: 0.3255 - val_loss: 1.4912 - val_accuracy: 0.3625\n",
            "Epoch 5/60\n",
            " 46/188 [======>.......................] - ETA: 18:48 - loss: 1.5018 - accuracy: 0.3444"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Don't forget to copy the previous training log to monitor the evolution of the accuracy across all epochs"
      ],
      "metadata": {
        "id": "JzO2hxFZrvRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model's performance\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"The tested accuracy is {test_accuracy} and the tested loss is {test_loss}\")"
      ],
      "metadata": {
        "id": "knDoRVeYrvRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ResNet101 CNN"
      ],
      "metadata": {
        "id": "6YbpntRLtXlI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##All base model's layers are frozen, and only the new layers are trainable"
      ],
      "metadata": {
        "id": "74zvx9DztXlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet101V2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "mKuG9fH9tXlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = ResNet101V2(weights=\"imagenet\", include_top=False, input_shape = (128, 128, 3)) #That is, 128x123 pixels over 3 channels (RGB)\n",
        "\n",
        "#Freezing the base_model'S layers\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "#Adding custom layers on top\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(64, activation = \"relu\"))\n",
        "model.add(Dense(len(sp_classes), activation=\"softmax\")) #The model finishes with a number of outputs equal to the number of classes in sp_classes\n",
        "\n",
        "#Compiling the model\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "fbcyw9MytXlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing training, validation and test data"
      ],
      "metadata": {
        "id": "4Ud2A57ZtXlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_batch_size = 32\n",
        "valid_batch_size = 32\n",
        "test_batch_size = 32\n",
        "\n",
        "#Training data\n",
        "print(\"For training data...\")\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255, # Rescale pixel values between 0 and 1\n",
        "    horizontal_flip=True, # Randomly flip images horizontally\n",
        "    vertical_flip=True, #Randomly flip images vertically\n",
        ")\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    batch_size=train_batch_size, # Set batch size\n",
        "    class_mode='categorical' # Use categorical labels for multi-class classification\n",
        ")\n",
        "\n",
        "#Validation data\n",
        "print(\"For validation data...\")\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255) # Only rescale for validation data\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    valid_path,\n",
        "    batch_size=valid_batch_size, # Set batch size\n",
        "    class_mode='categorical' # Use categorical labels for multi-class classification\n",
        ")\n",
        "\n",
        "#Test data\n",
        "print(\"For test data...\")\n",
        "test_datagen = ImageDataGenerator(rescale=1./255) # Only rescale for test data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    batch_size=test_batch_size, # Set batch size\n",
        "    class_mode='categorical' # Use categorical labels for multi-class classification\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e791442c-fe38-48a1-ca6e-72e10f8b3a26",
        "id": "vod3Gh0ltXlJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For training data...\n",
            "Found 6000 images belonging to 5 classes.\n",
            "For validation data...\n",
            "Found 2000 images belonging to 5 classes.\n",
            "For test data...\n",
            "Found 2000 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = os.path.join(data_dir, \"ResNet101V2_base-model-frzn.keras\")\n",
        "checkpoint = ModelCheckpoint(model_path, monitor = \"val_accuracy\", verbose=2, save_best_only=True, mode=\"max\") #The model will be saved every time an epoch shows an improvement in accuracy\n",
        "early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience=4, verbose=2, mode=\"max\")\n",
        "\n",
        "#Fit the model to the training data\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=60,\n",
        "    validation_data = valid_generator,\n",
        "    callbacks=[checkpoint, early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8f5796f-eadc-4244-f04e-179062f7665d",
        "id": "WyOyvWsYtXlJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "188/188 [==============================] - ETA: 0s - loss: 1.6084 - accuracy: 0.2497\n",
            "Epoch 1: val_accuracy improved from -inf to 0.31500, saving model to best_model.keras\n",
            "188/188 [==============================] - 2019s 11s/step - loss: 1.6084 - accuracy: 0.2497 - val_loss: 1.5550 - val_accuracy: 0.3150\n",
            "Epoch 2/60\n",
            "188/188 [==============================] - ETA: 0s - loss: 1.5772 - accuracy: 0.2850\n",
            "Epoch 2: val_accuracy did not improve from 0.31500\n",
            "188/188 [==============================] - 2000s 11s/step - loss: 1.5772 - accuracy: 0.2850 - val_loss: 1.5704 - val_accuracy: 0.2610\n",
            "Epoch 3/60\n",
            "188/188 [==============================] - ETA: 0s - loss: 1.5449 - accuracy: 0.3077\n",
            "Epoch 3: val_accuracy improved from 0.31500 to 0.32800, saving model to best_model.keras\n",
            "188/188 [==============================] - 1982s 11s/step - loss: 1.5449 - accuracy: 0.3077 - val_loss: 1.5788 - val_accuracy: 0.3280\n",
            "Epoch 4/60\n",
            "188/188 [==============================] - ETA: 0s - loss: 1.5213 - accuracy: 0.3255\n",
            "Epoch 4: val_accuracy improved from 0.32800 to 0.36250, saving model to best_model.keras\n",
            "188/188 [==============================] - 1995s 11s/step - loss: 1.5213 - accuracy: 0.3255 - val_loss: 1.4912 - val_accuracy: 0.3625\n",
            "Epoch 5/60\n",
            " 99/188 [==============>...............] - ETA: 11:51 - loss: 1.5166 - accuracy: 0.3365"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Don't forget to copy the previous training log to monitor the evolution of the accuracy across all epochs"
      ],
      "metadata": {
        "id": "pJlqfH1DtXlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model's performance\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"The tested accuracy is {test_accuracy} and the tested loss is {test_loss}\")"
      ],
      "metadata": {
        "id": "MCM67bKWtXlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Only the base model's first 2 layers are frozen, and the rest is trainable"
      ],
      "metadata": {
        "id": "I4zbLRshtXlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet101V2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "VkF69IuUtXlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = ResNet101V2(weights=\"imagenet\", include_top=False, input_shape = (128, 128, 3)) #That is, 128x123 pixels over 3 channels (RGB)\n",
        "\n",
        "#Freezing the first 2 layers\n",
        "for layer in base_model.layers[:2]:\n",
        "  layer.trainable = False\n",
        "\n",
        "#Adding custom layers on top\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(64, activation = \"relu\"))\n",
        "model.add(Dense(len(sp_classes), activation=\"softmax\")) #The model finishes with a number of outputs equal to the number of classes in sp_classes\n",
        "\n",
        "#Compiling the model\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "2x3443aGtXlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing training, validation and test data"
      ],
      "metadata": {
        "id": "U9uJxZl-tXlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_batch_size = 32\n",
        "valid_batch_size = 32\n",
        "test_batch_size = 32\n",
        "\n",
        "#Training data\n",
        "print(\"For training data...\")\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255, # Rescale pixel values between 0 and 1\n",
        "    horizontal_flip=True, # Randomly flip images horizontally\n",
        "    vertical_flip=True, #Randomly flip images vertically\n",
        ")\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    batch_size=train_batch_size, # Set batch size\n",
        "    class_mode='categorical' # Use categorical labels for multi-class classification\n",
        ")\n",
        "\n",
        "#Validation data\n",
        "print(\"For validation data...\")\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255) # Only rescale for validation data\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    valid_path,\n",
        "    batch_size=valid_batch_size, # Set batch size\n",
        "    class_mode='categorical' # Use categorical labels for multi-class classification\n",
        ")\n",
        "\n",
        "#Test data\n",
        "print(\"For test data...\")\n",
        "test_datagen = ImageDataGenerator(rescale=1./255) # Only rescale for test data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    batch_size=test_batch_size, # Set batch size\n",
        "    class_mode='categorical' # Use categorical labels for multi-class classification\n",
        ")"
      ],
      "metadata": {
        "id": "vRlN_g7FtXlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = os.path.join(data_dir, \"ResNet101V2_2-bottom-layers-frzn.keras\")\n",
        "checkpoint = ModelCheckpoint(model_path, monitor = \"val_accuracy\", verbose=2, save_best_only=True, mode=\"max\") #The model will be saved every time an epoch shows an improvement in accuracy\n",
        "early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience=4, verbose=2, mode=\"max\")\n",
        "\n",
        "#Fit the model to the training data\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=60,\n",
        "    validation_data = valid_generator,\n",
        "    callbacks=[checkpoint, early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "H1WFjMCitXlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Don't forget to copy the previous training log to monitor the evolution of the accuracy across all epochs"
      ],
      "metadata": {
        "id": "bo-M_MJetXlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model's performance\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"The tested accuracy is {test_accuracy} and the tested loss is {test_loss}\")"
      ],
      "metadata": {
        "id": "-aX23c8PtXlQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}